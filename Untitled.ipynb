{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70cc147-1d81-48a2-ba91-4064bcb089e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanil.utils import (\n",
    "    load_yaml, \n",
    "    set_seed, \n",
    "    get_device, \n",
    "    get_logger, \n",
    "    write_json,\n",
    "    LoggerConfig,\n",
    ")\n",
    "from cleanil.data import normalize, train_test_split  # Remove load_d4rl_expert_trajs\n",
    "from cleanil.il import iqlearn\n",
    "from cleanil.rl.actor import make_tanh_normal_actor\n",
    "from cleanil.rl.critic import DoubleQNetwork\n",
    "from torchrl.data import LazyTensorStorage, ReplayBuffer\n",
    "\n",
    "# Add your custom data loader\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "def load_custom_expert_trajs(dataset_name, num_expert_trajs, obs_dim, act_dim):\n",
    "    \"\"\"Your custom data loading function\"\"\"\n",
    "    # Load from HuggingFace datasets\n",
    "    dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    \n",
    "    # Convert to the required format (implement based on your dataset structure)\n",
    "    # This is a template - adjust based on your actual data format\n",
    "    trajectories = []\n",
    "    \n",
    "    for i, episode in enumerate(dataset):\n",
    "        if i >= num_expert_trajs:\n",
    "            break\n",
    "            \n",
    "        # Extract data - adjust these key names based on your dataset\n",
    "        observations = torch.tensor(episode['observations'], dtype=torch.float32)\n",
    "        actions = torch.tensor(episode['actions'], dtype=torch.float32)\n",
    "        \n",
    "        # Ensure correct shapes\n",
    "        if len(observations.shape) == 1:\n",
    "            observations = observations.unsqueeze(-1)\n",
    "        if len(actions.shape) == 1:\n",
    "            actions = actions.unsqueeze(-1)\n",
    "            \n",
    "        next_observations = torch.cat([observations[1:], observations[-1:]], dim=0)\n",
    "        episode_length = len(observations)\n",
    "        \n",
    "        from tensordict import TensorDict\n",
    "        episode_data = TensorDict({\n",
    "            'observation': observations,\n",
    "            'action': actions,\n",
    "            'reward': torch.zeros(episode_length, 1),\n",
    "            'terminated': torch.cat([torch.zeros(episode_length-1), torch.ones(1)]).bool(),\n",
    "            'truncated': torch.zeros(episode_length).bool(), \n",
    "            'done': torch.cat([torch.zeros(episode_length-1), torch.ones(1)]).bool(),\n",
    "            'next': TensorDict({\n",
    "                'observation': next_observations,\n",
    "                'reward': torch.zeros(episode_length, 1),\n",
    "                'terminated': torch.cat([torch.zeros(episode_length-1), torch.ones(1)]).bool(),\n",
    "                'truncated': torch.zeros(episode_length).bool(),\n",
    "                'done': torch.cat([torch.zeros(episode_length-1), torch.ones(1)]).bool(),\n",
    "            }, batch_size=[episode_length])\n",
    "        }, batch_size=[episode_length])\n",
    "        \n",
    "        trajectories.append(episode_data)\n",
    "    \n",
    "    if trajectories:\n",
    "        return torch.cat(trajectories, dim=0)\n",
    "    else:\n",
    "        raise ValueError(\"No trajectories loaded\")\n",
    "\n",
    "def main(**kwargs):\n",
    "    config = load_yaml(**kwargs)\n",
    "    algo_config = iqlearn.IQLearnConfig(**config[\"algo\"])\n",
    "    write_json(config, f\"{algo_config.save_path}/config.json\")\n",
    "\n",
    "    set_seed(config[\"seed\"])\n",
    "    device = get_device(config[\"device\"])\n",
    "    logger = get_logger(config, LoggerConfig(**config[\"logger\"]))\n",
    "    \n",
    "    print(\"device\", device)\n",
    "\n",
    "    # CHANGE 1: Define your data dimensions manually (no environment needed)\n",
    "    obs_dim = 4  # CartPole observation dimension\n",
    "    act_dim = 1  # CartPole action dimension (discrete -> continuous conversion needed)\n",
    "    action_bounds = (-1.0, 1.0)  # Set appropriate bounds\n",
    "\n",
    "    # CHANGE 2: Load your custom data instead of D4RL\n",
    "    expert_data = load_custom_expert_trajs(\n",
    "        \"NathanGavenski/CartPole-v1\",  # Your dataset name\n",
    "        algo_config.num_expert_trajs,\n",
    "        obs_dim,\n",
    "        act_dim\n",
    "    )\n",
    "    \n",
    "    expert_data = expert_data.to(device)\n",
    "    expert_data, eval_data = train_test_split(expert_data, algo_config.train_ratio)\n",
    "\n",
    "    # Normalize data\n",
    "    obs_mean = expert_data[\"observation\"].mean(0)\n",
    "    obs_std = expert_data[\"observation\"].std(0)\n",
    "    expert_data[\"observation\"] = normalize(expert_data[\"observation\"], obs_mean, obs_std**2)\n",
    "    expert_data[\"next\"][\"observation\"] = normalize(expert_data[\"next\"][\"observation\"], obs_mean, obs_std**2)\n",
    "    eval_data[\"observation\"] = normalize(eval_data[\"observation\"], obs_mean, obs_std**2)\n",
    "    eval_data[\"next\"][\"observation\"] = normalize(eval_data[\"next\"][\"observation\"], obs_mean, obs_std**2)\n",
    "    \n",
    "    # CHANGE 3: Create agent without environment specs\n",
    "    actor = make_tanh_normal_actor(\n",
    "        obs_dim, \n",
    "        act_dim, \n",
    "        algo_config.hidden_dims, \n",
    "        algo_config.activation,\n",
    "        torch.tensor([action_bounds[0]] * act_dim),  # Manual action bounds\n",
    "        torch.tensor([action_bounds[1]] * act_dim),\n",
    "    )\n",
    "    critic = DoubleQNetwork(\n",
    "        obs_dim, \n",
    "        act_dim, \n",
    "        algo_config.hidden_dims, \n",
    "        algo_config.activation,\n",
    "    )\n",
    "    actor.to(device)\n",
    "    critic.to(device)\n",
    "\n",
    "    # Make buffers\n",
    "    expert_buffer = ReplayBuffer(\n",
    "        storage=LazyTensorStorage(\n",
    "            len(expert_data), \n",
    "            device=device,\n",
    "        )\n",
    "    )\n",
    "    expert_buffer.extend(expert_data)\n",
    "\n",
    "    eval_buffer = ReplayBuffer(\n",
    "        storage=LazyTensorStorage(\n",
    "            len(eval_data), \n",
    "            device=device,\n",
    "        )\n",
    "    )\n",
    "    eval_buffer.extend(eval_data)\n",
    "\n",
    "    # CHANGE 4: Create trainer without eval_env\n",
    "    trainer = iqlearn.OfflineTrainer(  # Use modified trainer\n",
    "        algo_config,\n",
    "        actor,\n",
    "        critic,\n",
    "        expert_buffer,\n",
    "        eval_buffer,\n",
    "        obs_mean,\n",
    "        obs_std,\n",
    "        act_dim,  # Pass action dimension instead of env\n",
    "        logger,\n",
    "        device,\n",
    "    )\n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a7db6ca-5192-4e87-ab1b-c894049fd159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--config_path CONFIG_PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/ashish_panchal/.local/share/jupyter/runtime/kernel-82f05f1c-f808-40eb-84a3-add4e52ac70d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "main(config_path =\"configs/il/iqlearn/offline_cartpole.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c2958-082d-48c1-9fd9-4bb0bf0c773f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0c530-959e-498f-a927-a11d4e67e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/il/train_iqlearn_offline_hf.py --config configs/il/iqlearn/offline_cartpole.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d31d68-2ab6-4c0c-b7e8-0761c3069843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ashish_env_cleanil",
   "language": "python",
   "name": "ashish_env_cleanil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
