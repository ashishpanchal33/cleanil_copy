{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a731ca-8026-43f9-96fe-90997ed8b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export PYTHONPATH=\"$(pwd):$PYTHONPATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70cc147-1d81-48a2-ba91-4064bcb089e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanil.utils import (\n",
    "    load_yaml, \n",
    "    set_seed, \n",
    "    get_device, \n",
    "    get_logger, \n",
    "    write_json,\n",
    "    LoggerConfig,\n",
    ")\n",
    "from cleanil.data import normalize, train_test_split  # Remove load_d4rl_expert_trajs\n",
    "from cleanil.il import iqlearn\n",
    "from cleanil.rl.actor import make_tanh_normal_actor\n",
    "from cleanil.rl.critic import DoubleQNetwork\n",
    "from torchrl.data import LazyTensorStorage, ReplayBuffer\n",
    "\n",
    "# Add your custom data loader\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "def load_custom_expert_trajs(dataset_name, num_expert_trajs, obs_dim, act_dim):\n",
    "    \"\"\"Your custom data loading function\"\"\"\n",
    "    # Load from HuggingFace datasets\n",
    "    dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    \n",
    "    # Convert to the required format (implement based on your dataset structure)\n",
    "    # This is a template - adjust based on your actual data format\n",
    "    trajectories = []\n",
    "    \n",
    "    for i, episode in enumerate(dataset):\n",
    "        if i >= num_expert_trajs:\n",
    "            break\n",
    "            \n",
    "        # Extract data - adjust these key names based on your dataset\n",
    "        observations = torch.tensor(episode['observations'], dtype=torch.float32)\n",
    "        actions = torch.tensor(episode['actions'], dtype=torch.float32)\n",
    "        \n",
    "        # Ensure correct shapes\n",
    "        if len(observations.shape) == 1:\n",
    "            observations = observations.unsqueeze(-1)\n",
    "        if len(actions.shape) == 1:\n",
    "            actions = actions.unsqueeze(-1)\n",
    "            \n",
    "        next_observations = torch.cat([observations[1:], observations[-1:]], dim=0)\n",
    "        episode_length = len(observations)\n",
    "        \n",
    "        from tensordict import TensorDict\n",
    "        episode_data = TensorDict({\n",
    "            'observation': observations,\n",
    "            'action': actions,\n",
    "            'reward': torch.zeros(episode_length, 1),\n",
    "            'terminated': torch.cat([torch.zeros(episode_length-1), torch.ones(1)]).bool(),\n",
    "            'truncated': torch.zeros(episode_length).bool(), \n",
    "            'done': torch.cat([torch.zeros(episode_length-1), torch.ones(1)]).bool(),\n",
    "            'next': TensorDict({\n",
    "                'observation': next_observations,\n",
    "                'reward': torch.zeros(episode_length, 1),\n",
    "                'terminated': torch.cat([torch.zeros(episode_length-1), torch.ones(1)]).bool(),\n",
    "                'truncated': torch.zeros(episode_length).bool(),\n",
    "                'done': torch.cat([torch.zeros(episode_length-1), torch.ones(1)]).bool(),\n",
    "            }, batch_size=[episode_length])\n",
    "        }, batch_size=[episode_length])\n",
    "        \n",
    "        trajectories.append(episode_data)\n",
    "    \n",
    "    if trajectories:\n",
    "        return torch.cat(trajectories, dim=0)\n",
    "    else:\n",
    "        raise ValueError(\"No trajectories loaded\")\n",
    "\n",
    "def main(**kwargs):\n",
    "    config = load_yaml(**kwargs)\n",
    "    algo_config = iqlearn.IQLearnConfig(**config[\"algo\"])\n",
    "    write_json(config, f\"{algo_config.save_path}/config.json\")\n",
    "\n",
    "    set_seed(config[\"seed\"])\n",
    "    device = get_device(config[\"device\"])\n",
    "    logger = get_logger(config, LoggerConfig(**config[\"logger\"]))\n",
    "    \n",
    "    print(\"device\", device)\n",
    "\n",
    "    # CHANGE 1: Define your data dimensions manually (no environment needed)\n",
    "    obs_dim = 4  # CartPole observation dimension\n",
    "    act_dim = 1  # CartPole action dimension (discrete -> continuous conversion needed)\n",
    "    action_bounds = (-1.0, 1.0)  # Set appropriate bounds\n",
    "\n",
    "    # CHANGE 2: Load your custom data instead of D4RL\n",
    "    expert_data = load_custom_expert_trajs(\n",
    "        \"NathanGavenski/CartPole-v1\",  # Your dataset name\n",
    "        algo_config.num_expert_trajs,\n",
    "        obs_dim,\n",
    "        act_dim\n",
    "    )\n",
    "    \n",
    "    expert_data = expert_data.to(device)\n",
    "    expert_data, eval_data = train_test_split(expert_data, algo_config.train_ratio)\n",
    "\n",
    "    # Normalize data\n",
    "    obs_mean = expert_data[\"observation\"].mean(0)\n",
    "    obs_std = expert_data[\"observation\"].std(0)\n",
    "    expert_data[\"observation\"] = normalize(expert_data[\"observation\"], obs_mean, obs_std**2)\n",
    "    expert_data[\"next\"][\"observation\"] = normalize(expert_data[\"next\"][\"observation\"], obs_mean, obs_std**2)\n",
    "    eval_data[\"observation\"] = normalize(eval_data[\"observation\"], obs_mean, obs_std**2)\n",
    "    eval_data[\"next\"][\"observation\"] = normalize(eval_data[\"next\"][\"observation\"], obs_mean, obs_std**2)\n",
    "    \n",
    "    # CHANGE 3: Create agent without environment specs\n",
    "    actor = make_tanh_normal_actor(\n",
    "        obs_dim, \n",
    "        act_dim, \n",
    "        algo_config.hidden_dims, \n",
    "        algo_config.activation,\n",
    "        torch.tensor([action_bounds[0]] * act_dim),  # Manual action bounds\n",
    "        torch.tensor([action_bounds[1]] * act_dim),\n",
    "    )\n",
    "    critic = DoubleQNetwork(\n",
    "        obs_dim, \n",
    "        act_dim, \n",
    "        algo_config.hidden_dims, \n",
    "        algo_config.activation,\n",
    "    )\n",
    "    actor.to(device)\n",
    "    critic.to(device)\n",
    "\n",
    "    # Make buffers\n",
    "    expert_buffer = ReplayBuffer(\n",
    "        storage=LazyTensorStorage(\n",
    "            len(expert_data), \n",
    "            device=device,\n",
    "        )\n",
    "    )\n",
    "    expert_buffer.extend(expert_data)\n",
    "\n",
    "    eval_buffer = ReplayBuffer(\n",
    "        storage=LazyTensorStorage(\n",
    "            len(eval_data), \n",
    "            device=device,\n",
    "        )\n",
    "    )\n",
    "    eval_buffer.extend(eval_data)\n",
    "\n",
    "    # CHANGE 4: Create trainer without eval_env\n",
    "    trainer = iqlearn.OfflineTrainer(  # Use modified trainer\n",
    "        algo_config,\n",
    "        actor,\n",
    "        critic,\n",
    "        expert_buffer,\n",
    "        eval_buffer,\n",
    "        obs_mean,\n",
    "        obs_std,\n",
    "        act_dim,  # Pass action dimension instead of env\n",
    "        logger,\n",
    "        device,\n",
    "    )\n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a7db6ca-5192-4e87-ab1b-c894049fd159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--config_path CONFIG_PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/ashish_panchal/.local/share/jupyter/runtime/kernel-82f05f1c-f808-40eb-84a3-add4e52ac70d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "main(config_path =\"configs/il/iqlearn/offline_cartpole.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c2958-082d-48c1-9fd9-4bb0bf0c773f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0c530-959e-498f-a927-a11d4e67e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/il/train_iqlearn_offline_hf.py --config configs/il/iqlearn/offline_cartpole.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d31d68-2ab6-4c0c-b7e8-0761c3069843",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/il/train_iqlearn_offline_hf_discrete.py --config configs/il/iqlearn/offline_cartpole_discrete.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be9b5b2-8309-4887-bbab-d588d312a693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ashish_panchal/Ashish_exp_set_1/IQ_learn/cleanil_copy/scripts/il/train_iqlearn_offline_hf_discrete.py\", line 1, in <module>\n",
      "    from cleanil.utils import (\n",
      "ModuleNotFoundError: No module named 'cleanil'\n"
     ]
    }
   ],
   "source": [
    "!python scripts/il/train_iqlearn_offline_hf_discrete.py --config  configs/il/iqlearn/offline_lunarlander_discrete.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1a2e9-6bdf-402c-be18-69dd4077e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/il/train_iqlearn_offline_hf_discrete.py --config configs/il/iqlearn/offline_rust_discrete.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e73f4d8a-553e-499a-bb72-9dfce3edb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensordict import TensorDict\n",
    "\n",
    "def hf_to_tensordict_discrete(dataset_name, split=\"train\"):\n",
    "    ds = load_dataset(dataset_name, split=split)\n",
    "    \n",
    "    obs = torch.tensor(ds[\"obs\"], dtype=torch.float32)\n",
    "    # Keep actions as discrete integers but add dimension for compatibility\n",
    "    actions = torch.tensor(ds[\"actions\"], dtype=torch.long)#.unsqueeze(-1)\n",
    "    rewards = torch.tensor(ds[\"rewards\"], dtype=torch.float32).unsqueeze(-1)\n",
    "    starts = torch.tensor(ds[\"episode_starts\"], dtype=torch.bool)\n",
    "\n",
    "\n",
    "    \n",
    "    actions = torch.tensor(ds[\"actions\"], dtype=torch.float32)   # [T, act_dim]\n",
    "\n",
    "    \n",
    "    \n",
    "    rewards = torch.tensor(ds[\"rewards\"], dtype=torch.float32).unsqueeze(-1)  # [T,1]\n",
    "    starts = torch.tensor(ds[\"episode_starts\"], dtype=torch.bool) # [T]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    T = obs.shape[0]\n",
    "    terminated = starts.roll(-1, dims=0)\n",
    "    terminated[-1] = True\n",
    "    truncated = torch.zeros_like(terminated)\n",
    "    done = terminated | truncated\n",
    "    \n",
    "    next_obs = obs.roll(-1, dims=0)\n",
    "    next_obs[-1] = obs[-1]\n",
    "    \n",
    "    td = TensorDict({\n",
    "        \"observation\": obs,\n",
    "        \"action\": actions,\n",
    "        \"reward\": rewards,\n",
    "        \"terminated\": terminated,\n",
    "        \"truncated\": truncated,\n",
    "        \"done\": done,\n",
    "        \"next\": TensorDict({\n",
    "            \"observation\": next_obs,\n",
    "            \"reward\": rewards,\n",
    "            \"terminated\": terminated,\n",
    "            \"truncated\": truncated,\n",
    "            \"done\": done,\n",
    "        }, batch_size=[T]),\n",
    "    }, batch_size=[T])\n",
    "    \n",
    "    return td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b9c8844-1bea-4b8a-ac04-3563137323d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383.994"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "383994/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aaf2ad1-27ce-4027-99a8-7acbbe36d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|â–ˆ| 383994/383994 [00:00<00:00, 513962.09 examples/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([383994]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([383994]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                done: Tensor(shape=torch.Size([383994]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([383994, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                reward: Tensor(shape=torch.Size([383994, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([383994]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([383994]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([383994]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([383994, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        reward: Tensor(shape=torch.Size([383994, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([383994]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        truncated: Tensor(shape=torch.Size([383994]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([383994]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_to_tensordict_discrete(\"NathanGavenski/LunarLander-v2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ashish_env_cleanil",
   "language": "python",
   "name": "ashish_env_cleanil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
